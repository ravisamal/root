{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data from Twitter \n",
    "# Tweepy module is used\n",
    "# Now in order to authorize our app to access Twitter on our behalf, we need to use the OAuth Interface. Tweepy provides the convenient Cursor interface to iterate through different types of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Tweets                   id  \\\n",
      "0                     @rahulkanojia98 Before 14 April.  1116170212443734016   \n",
      "1    Considering several requests to extend the dea...  1116061280337457152   \n",
      "2    We will close the submission portal in 15 min....  1116046513002573825   \n",
      "3    RT @RatnRajiv: @midasIIITD @IIITDelhi @Hitkul_...  1116038332629184512   \n",
      "4    @midasIIITD lab is looking for motivated MTech...  1116024512657543168   \n",
      "5    We will close the submission portal for submit...  1116019868053041152   \n",
      "6    Clarification: Our earlier post which indicate...  1115902611599822852   \n",
      "7    RT @IIITDelhi: Applications open for MTech (CB...  1115839682607239173   \n",
      "8    RT @IIITDelhi: We are delighted to share that ...  1115656899892879361   \n",
      "9    RT @Harvard: Professor Jelani Nelson founded A...  1115480571323371520   \n",
      "10   RT @emnlp2019: For anyone interested in submit...  1115480504931844101   \n",
      "11   RT @multimediaeval: Announcing the 2019 MediaE...  1115338057400573953   \n",
      "12   Many Congratulations to @midasIIITD student, S...  1115149324533542912   \n",
      "13   @midasIIITD thanks all students who have appea...  1115093836341096449   \n",
      "14   @himanchalchandr Meanwhile, complete CV/NLP ta...  1114894970886983680   \n",
      "15   @sayangdipto123 Submit as per the guideline ag...  1114894886292029440   \n",
      "16   We request all students whose interview are sc...  1114856195335106560   \n",
      "17   Other queries: \"none of the Tweeter Apis give ...  1114783695129534464   \n",
      "18   Other queries: \"do we have to make two differe...  1114783273757151232   \n",
      "19   Other queries: \"If using Twitter api, it does ...  1114762841637175296   \n",
      "20   Response to some queries asked by students on ...  1114762141259763712   \n",
      "21   RT @kdnuggets: Top 8 #Free Must-Read #Books on...  1114576370414292992   \n",
      "22   @nupur_baghel @PennDATS Congratulation @nupur_...  1114569315636928512   \n",
      "23   We have emailed the task details to all candid...  1114198161562775553   \n",
      "24   RT @rfpvjr: Our NAACL paper on polarization in...  1114016105079693312   \n",
      "25   RT @kdnuggets: Effective Transfer Learning For...  1114015987395854336   \n",
      "26   RT @stanfordnlp: Whatâ€™s new in @Stanford CS224...  1113509442849525760   \n",
      "27   RT @DeepMindAI: Today we're releasing a large-...  1113487457780215808   \n",
      "28   RT @ylecun: Congratulations Jitendra Malik !\\n...  1113366445231104001   \n",
      "29   RT @IIITDelhi: Another chance to take admissio...  1113346906007265280   \n",
      "..                                                 ...                  ...   \n",
      "170              @abhinavdhall @RatnRajiv Emailed you.  1084490450579279874   \n",
      "171  RT @kdnuggets: A comprehensive list of #Machin...  1084481048891731973   \n",
      "172  Call for Book Chapter- Springer- Deep learning...  1084349153566543872   \n",
      "173  RT @Stanford: The average woman is exposed to ...  1084096944765493248   \n",
      "174  @harvardmed @Harvard Another interesting direc...  1083285146621624321   \n",
      "175  RT @harvardmed: A first-of-its-kind strategy a...  1083284960541208576   \n",
      "176  RT @RatnRajiv: Fortunate to have appreciation ...  1083284382192787456   \n",
      "177  RT @Harvard: The study provides potential futu...  1082820527427735552   \n",
      "178  RT @UniofOxford: In the final episode of serie...  1082201475504267265   \n",
      "179  @ACMMM19: Call for Workshop Proposals \\n\\nDead...  1081896689810567168   \n",
      "180  @ACMMM19: Call for Grand Challenge Proposals\\n...  1081769684570058752   \n",
      "181  Since 1993, ACM Multimedia has been bringing t...  1081764771081285632   \n",
      "182  @ACMMM19 is structured around four themes (alp...  1081764163171446785   \n",
      "183  ACM Multimedia 2019: First Call for Papers/Cal...  1081763698648113152   \n",
      "184  RT @ACMMM19: Happy new year! 2019 started with...  1080708859033989120   \n",
      "185  You may follow @midasIIITD updates through fol...  1080152125630500864   \n",
      "186  Today, @midasIIITD completed one year at @IIIT...  1080151147434913793   \n",
      "187  RT @debanjanbhucs: Happy anniversary to @midas...  1080135158295154689   \n",
      "188  Two Research Assistant (RA) positions are stil...  1078236176740282369   \n",
      "189  Positions for two Research Assistants (RA) are...  1078228773554667520   \n",
      "190  RT @TCoolsIT: I wrote a blogpost on CoreNLP hi...  1078116750439243776   \n",
      "191  @RatnRajiv delivered a research talk at the Ce...  1077861845652824065   \n",
      "192  @midasIIITD look forward to work together. htt...  1077417463258566656   \n",
      "193  @the_dhumketu @punnibhai @Hitkul_, FYI. https:...  1077398614966599680   \n",
      "194  RT @iiit_hyderabad: KCIS Distinguished Lecture...  1077106437673803776   \n",
      "195  RT @StanfordAILab: Our latest blog post is out...  1075961723322945536   \n",
      "196  RT @medialab: In two new papers, @PratikShahPh...  1075814483304448000   \n",
      "197  RT @RatnRajiv: Wonderful get together with our...  1075635627293519874   \n",
      "198  @ACMMM19 is the premier international conferen...  1075213255818104832   \n",
      "199  Feel free to contact us if you have any query ...  1075038589505990656   \n",
      "\n",
      "     len       date and time              source  likes  retweets  \\\n",
      "0     32 2019-04-11 02:44:50  Twitter Web Client      0         0   \n",
      "1    140 2019-04-10 19:31:59  Twitter Web Client      0         0   \n",
      "2    102 2019-04-10 18:33:18  Twitter Web Client      0         0   \n",
      "3    139 2019-04-10 18:00:48  Twitter Web Client      0         2   \n",
      "4    140 2019-04-10 17:05:53  Twitter Web Client      4         3   \n",
      "5    140 2019-04-10 16:47:25  Twitter Web Client      2         1   \n",
      "6    139 2019-04-10 09:01:29  Twitter Web Client      1         0   \n",
      "7    139 2019-04-10 04:51:26  Twitter Web Client      0         1   \n",
      "8    140 2019-04-09 16:45:07  Twitter Web Client      0        14   \n",
      "9    136 2019-04-09 05:04:27  Twitter Web Client      0        36   \n",
      "10   140 2019-04-09 05:04:11  Twitter Web Client      0        17   \n",
      "11   140 2019-04-08 19:38:09  Twitter Web Client      0        15   \n",
      "12   140 2019-04-08 07:08:12  Twitter Web Client     18         2   \n",
      "13   140 2019-04-08 03:27:42  Twitter Web Client      6         0   \n",
      "14    55 2019-04-07 14:17:29  Twitter Web Client      0         0   \n",
      "15    50 2019-04-07 14:17:09  Twitter Web Client      0         0   \n",
      "16   140 2019-04-07 11:43:24  Twitter Web Client      1         1   \n",
      "17   139 2019-04-07 06:55:19  Twitter Web Client      5         2   \n",
      "18   140 2019-04-07 06:53:38  Twitter Web Client      5         1   \n",
      "19   140 2019-04-07 05:32:27  Twitter Web Client      6         1   \n",
      "20   140 2019-04-07 05:29:40  Twitter Web Client      7         1   \n",
      "21    89 2019-04-06 17:11:29  Twitter Web Client      0         2   \n",
      "22   140 2019-04-06 16:43:27  Twitter Web Client     18         3   \n",
      "23   140 2019-04-05 16:08:37  Twitter Web Client     11         1   \n",
      "24   139 2019-04-05 04:05:11  Twitter Web Client      0        16   \n",
      "25    98 2019-04-05 04:04:43  Twitter Web Client      0        11   \n",
      "26   140 2019-04-03 18:31:53  Twitter Web Client      0        59   \n",
      "27   140 2019-04-03 17:04:32  Twitter Web Client      0       874   \n",
      "28   113 2019-04-03 09:03:40  Twitter Web Client      0        16   \n",
      "29   140 2019-04-03 07:46:02  Twitter Web Client      0         4   \n",
      "..   ...                 ...                 ...    ...       ...   \n",
      "170   37 2019-01-13 16:40:46  Twitter Web Client      0         0   \n",
      "171  140 2019-01-13 16:03:25  Twitter Web Client      0        41   \n",
      "172  138 2019-01-13 07:19:19  Twitter Web Client      6         1   \n",
      "173  140 2019-01-12 14:37:07  Twitter Web Client      0        48   \n",
      "174   89 2019-01-10 08:51:20  Twitter Web Client      1         0   \n",
      "175  140 2019-01-10 08:50:35  Twitter Web Client      0        27   \n",
      "176  140 2019-01-10 08:48:17  Twitter Web Client      0         3   \n",
      "177  123 2019-01-09 02:05:06  Twitter Web Client      0         9   \n",
      "178  140 2019-01-07 09:05:12  Twitter Web Client      0        16   \n",
      "179  133 2019-01-06 12:54:06  Twitter Web Client      1         0   \n",
      "180  127 2019-01-06 04:29:25  Twitter Web Client      1         0   \n",
      "181  140 2019-01-06 04:09:54  Twitter Web Client      5         1   \n",
      "182  140 2019-01-06 04:07:29  Twitter Web Client      1         0   \n",
      "183  139 2019-01-06 04:05:38  Twitter Web Client      4         2   \n",
      "184  140 2019-01-03 06:14:05  Twitter Web Client      0         2   \n",
      "185  122 2019-01-01 17:21:49  Twitter Web Client      4         2   \n",
      "186  140 2019-01-01 17:17:56  Twitter Web Client     14         5   \n",
      "187  140 2019-01-01 16:14:24  Twitter Web Client      0         4   \n",
      "188  139 2018-12-27 10:28:31  Twitter Web Client      2         1   \n",
      "189  140 2018-12-27 09:59:06  Twitter Web Client      5         3   \n",
      "190  139 2018-12-27 02:33:58  Twitter Web Client      0        12   \n",
      "191  140 2018-12-26 09:41:04  Twitter Web Client     14         2   \n",
      "192   66 2018-12-25 04:15:15  Twitter Web Client      1         0   \n",
      "193   63 2018-12-25 03:00:21  Twitter Web Client      2         1   \n",
      "194  140 2018-12-24 07:39:21  Twitter Web Client      0        12   \n",
      "195  139 2018-12-21 03:50:39  Twitter Web Client      0        32   \n",
      "196  140 2018-12-20 18:05:35  Twitter Web Client      0         8   \n",
      "197  139 2018-12-20 06:14:52  Twitter Web Client      0         3   \n",
      "198  140 2018-12-19 02:16:31  Twitter Web Client      2         3   \n",
      "199  140 2018-12-18 14:42:27  Twitter Web Client      3         2   \n",
      "\n",
      "     no_of_images  \n",
      "0              11  \n",
      "1              11  \n",
      "2              11  \n",
      "3              11  \n",
      "4              11  \n",
      "5              11  \n",
      "6              11  \n",
      "7              11  \n",
      "8              11  \n",
      "9              11  \n",
      "10             11  \n",
      "11             11  \n",
      "12             11  \n",
      "13             11  \n",
      "14             11  \n",
      "15             11  \n",
      "16             11  \n",
      "17             11  \n",
      "18             11  \n",
      "19             11  \n",
      "20             11  \n",
      "21             11  \n",
      "22             11  \n",
      "23             11  \n",
      "24             11  \n",
      "25             11  \n",
      "26             11  \n",
      "27             11  \n",
      "28             11  \n",
      "29             11  \n",
      "..            ...  \n",
      "170            11  \n",
      "171            11  \n",
      "172            11  \n",
      "173            11  \n",
      "174            11  \n",
      "175            11  \n",
      "176            11  \n",
      "177            11  \n",
      "178            11  \n",
      "179            11  \n",
      "180            11  \n",
      "181            11  \n",
      "182            11  \n",
      "183            11  \n",
      "184            11  \n",
      "185            11  \n",
      "186            11  \n",
      "187            11  \n",
      "188            11  \n",
      "189            11  \n",
      "190            11  \n",
      "191            11  \n",
      "192            11  \n",
      "193            11  \n",
      "194            11  \n",
      "195            11  \n",
      "196            11  \n",
      "197            11  \n",
      "198            11  \n",
      "199            11  \n",
      "\n",
      "[200 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from tweepy import API \n",
    "from tweepy import Cursor\n",
    "from tweepy import OAuthHandler\n",
    "#After creating the Twitter Application enter the keys. \n",
    "ACCESS_TOKEN = \"enter_token_key\"  \n",
    "ACCESS_TOKEN_SECRET = \"enter_acess_secret_token_key\"\n",
    "CONSUMER_KEY = \"enter_consumer_key\"\n",
    "CONSUMER_SECRET = \"enter_consumer_secret_key\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class TweetAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing and categorizing content from tweets.\n",
    "    \"\"\"\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df['date and time'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        \n",
    "        count=0\n",
    "        for tweet in tweets:\n",
    "            if 'media' in tweet.entities:\n",
    "                for image in  tweet.entities['media']:\n",
    "                    count=count+1\n",
    "        df['no_of_images']  =count\n",
    "            \n",
    "        return df\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=\"midasIIITD\",count = 350)\n",
    "    #print(dir(tweets[0]))\n",
    "    #print(tweets[0].retweet_count)\n",
    "    with open('temp.json', 'w') as f:\n",
    "        f.write(df.to_json(orient='records', lines=True))\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    \n",
    "    print(df.head(350))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
